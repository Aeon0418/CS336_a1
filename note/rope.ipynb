{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2227075b",
   "metadata": {},
   "source": [
    "# 手写RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef032c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rope(\n",
    "    d_k: int,\n",
    "    theta: float,\n",
    "    max_seq_len: int,\n",
    "    in_query_or_key: Float[Tensor, \" ... sequence_length d_k\"],\n",
    "    token_positions: Int[Tensor, \" ... sequence_length\"],\n",
    ") -> Float[Tensor, \" ... sequence_length d_k\"]:\n",
    "    \"\"\"\n",
    "    为给定输入张量运行RoPE。\n",
    "\n",
    "    参数:\n",
    "        d_k (int): 查询或键张量的嵌入维度大小。\n",
    "        theta (float): RoPE参数。\n",
    "        max_seq_len (int): 如果你的实现预缓存的最大序列长度。\n",
    "        in_query_or_key (Float[Tensor, \"... sequence_length d_k\"]): 运行RoPE的输入张量。\n",
    "        token_positions (Int[Tensor, \"... sequence_length\"]): 形状为(batch_size, sequence_length)的张量，包含token位置\n",
    "    返回:\n",
    "        Float[Tensor, \" ... sequence_length d_k\"]: 应用RoPE的输入张量。\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary Positional Embedding (RoPE)\n",
    "    \n",
    "    RoPE 是一种新型的位置编码方法，通过旋转矩阵将位置信息编码到特征向量中。\n",
    "    相比传统的绝对位置编码，RoPE 具有更好的相对位置建模能力和外推性。\n",
    "    \n",
    "    核心思想：\n",
    "    - 将特征向量看作复数，通过旋转角度来编码位置信息\n",
    "    - 每个位置对应不同的旋转角度\n",
    "    - 不同特征维度使用不同的旋转频率\n",
    "    \n",
    "    数学原理：\n",
    "    对于位置 m 和特征维度 i，旋转角度为：θ_i * m\n",
    "    其中 θ_i = θ^(-2i/d_k)，θ 是基础频率参数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device=None):\n",
    "        \"\"\"\n",
    "        初始化 RoPE 模块\n",
    "        \n",
    "        参数:\n",
    "            theta (float): 基础角度参数，控制旋转频率的基数\n",
    "                          通常设为 10000.0，类似于 Transformer 原始位置编码\n",
    "                          较大的 theta 意味着较低的基础频率\n",
    "            d_k (int): 特征维度大小，必须是偶数\n",
    "                       因为 RoPE 将相邻的特征对 (x_i, x_{i+1}) 看作复数进行旋转\n",
    "            max_seq_len (int): 支持的最大序列长度\n",
    "                              预计算这个长度内所有位置的 cos/sin 值\n",
    "            device: 张量存储设备 (cpu/cuda)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 确保 d_k 是偶数，因为我们将特征维度成对处理\n",
    "        assert d_k % 2 == 0, f\"d_k must be even, got {d_k}\"\n",
    "        \n",
    "        # 1. 计算每个特征维度对的基础频率\n",
    "        # torch.arange(0, d_k, 2): [0, 2, 4, ..., d_k-2] - 偶数索引\n",
    "        # 形状: [d_k // 2]\n",
    "        # 这些索引对应特征对的索引 (0,1), (2,3), (4,5), ...\n",
    "        indices = torch.arange(0, d_k, 2, device=device, dtype=torch.float)\n",
    "        \n",
    "        # 计算 θ_i = θ^(-2i/d_k)，每个特征对的基础旋转频率\n",
    "        # 越靠后的特征维度，旋转频率越低（角度变化越慢）\n",
    "        # 形状: [d_k // 2]\n",
    "        theta_ik = theta ** (-indices / d_k)\n",
    "        \n",
    "        # 2. 计算所有位置的位置索引\n",
    "        # pos: [0, 1, 2, ..., max_seq_len-1]\n",
    "        # 形状: [max_seq_len]\n",
    "        pos = torch.arange(max_seq_len, device=device, dtype=torch.float)\n",
    "        \n",
    "        # 3. 计算所有 (位置, 特征维度对) 的旋转角度\n",
    "        # einsum \"i,j->ij\": pos[i] * theta_ik[j]\n",
    "        # 结果: angles[m][i] = m * θ_i，表示位置 m 在第 i 个特征对上的旋转角度\n",
    "        # 形状: [max_seq_len, d_k // 2]\n",
    "        angles = torch.einsum(\"i,j->ij\", pos, theta_ik)\n",
    "        \n",
    "        # 4. 预计算所有角度的 cos 和 sin 值\n",
    "        # 这些是旋转矩阵的基础元素\n",
    "        # 使用 register_buffer 将它们注册为模型的非参数张量\n",
    "        # persistent=False 表示在保存模型时不包含这些缓冲区（可以重新计算）\n",
    "        self.register_buffer(\"cos\", torch.cos(angles), persistent=False)\n",
    "        self.register_buffer(\"sin\", torch.sin(angles), persistent=False)\n",
    "        \n",
    "        # 存储维度信息用于调试\n",
    "        self.d_k = d_k\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        对输入张量应用 RoPE 位置编码\n",
    "        \n",
    "        参数:\n",
    "            x: 输入张量，形状为 [..., d_k]\n",
    "               通常是 (batch_size, num_heads, seq_len, d_k) 或 (batch_size, seq_len, d_k)\n",
    "               最后一个维度必须等于 d_k\n",
    "            token_positions: 位置索引张量，形状与 x 的前几个维度兼容\n",
    "                           包含每个 token 在序列中的位置 (0, 1, 2, ...)\n",
    "                           例如: [0, 1, 2, 3] 表示序列中的第0到第3个位置\n",
    "        \n",
    "        返回:\n",
    "            应用 RoPE 后的张量，形状与输入 x 相同 [..., d_k]\n",
    "        \n",
    "        RoPE 变换过程:\n",
    "        1. 将特征向量按维度分成实部和虚部 (x1, x2)\n",
    "        2. 根据位置获取对应的旋转角度的 cos 和 sin\n",
    "        3. 应用 2D 旋转矩阵进行旋转\n",
    "        4. 重新组合成原始形状\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. 根据位置索引获取对应的 cos 和 sin 值\n",
    "        # cos/sin: [max_seq_len, d_k // 2]\n",
    "        # token_positions: [...] - 任意形状的位置索引\n",
    "        # 结果: [..., d_k // 2] - 每个位置对应的旋转参数\n",
    "        cos = self.cos[token_positions]  # 形状: [..., d_k // 2]\n",
    "        sin = self.sin[token_positions]  # 形状: [..., d_k // 2]\n",
    "        \n",
    "        # 2. 将输入特征分解为相邻的特征对\n",
    "        # 把特征维度看作复数：(x_0, x_1), (x_2, x_3), ..., (x_{d_k-2}, x_{d_k-1})\n",
    "        # x1: 偶数索引特征 [x_0, x_2, x_4, ...] - 复数的实部\n",
    "        # x2: 奇数索引特征 [x_1, x_3, x_5, ...] - 复数的虚部\n",
    "        x1 = x[..., 0::2]  # 形状: [..., d_k // 2] - 从索引0开始，每隔2个取一个\n",
    "        x2 = x[..., 1::2]  # 形状: [..., d_k // 2] - 从索引1开始，每隔2个取一个\n",
    "        \n",
    "        # 3. 应用 2D 旋转矩阵\n",
    "        # 旋转矩阵: [[cos, -sin],\n",
    "        #           [sin,  cos]]\n",
    "        # 对复数 z = x1 + i*x2 进行旋转: z' = z * e^(iθ) = z * (cos + i*sin)\n",
    "        # 实部: x1' = x1*cos - x2*sin\n",
    "        # 虚部: x2' = x1*sin + x2*cos\n",
    "        rotated_x1 = x1 * cos - x2 * sin  # 新的实部\n",
    "        rotated_x2 = x1 * sin + x2 * cos  # 新的虚部\n",
    "        \n",
    "        # 4. 重新组合特征维度\n",
    "        # torch.stack(..., dim=-1): 将 rotated_x1 和 rotated_x2 在最后一个维度堆叠\n",
    "        # 形状变化: [..., d_k // 2] -> [..., d_k // 2, 2]\n",
    "        # flatten(-2): 将最后两个维度展平\n",
    "        # 形状变化: [..., d_k // 2, 2] -> [..., d_k]\n",
    "        # 最终结果: [rotated_x1[0], rotated_x2[0], rotated_x1[1], rotated_x2[1], ...]\n",
    "        out = torch.stack([rotated_x1, rotated_x2], dim=-1).flatten(-2)\n",
    "        \n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
